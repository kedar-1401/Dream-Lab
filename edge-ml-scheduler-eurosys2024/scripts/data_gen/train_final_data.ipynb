{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Requires minibatch_index_list file and powermode runs (Use detect_clean_mbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_data_time(sampled_powermodes, path, filename, offset_dict):\n",
    "    cpu_cores_multipler = 1\n",
    "    cpu_frq_divider = 1\n",
    "    gpu_frq_divider = 1\n",
    "    mem_frq_divider = 1\n",
    "\n",
    "    all_data = []\n",
    "\n",
    "    for powermode in sampled_powermodes:\n",
    "        # Get the offset before scaling\n",
    "        offset = offset_dict.get(powermode, -1)\n",
    "        file = path + \"/\" + \"pm_\" + powermode + \"/\" + filename\n",
    "        cores = int(powermode.split(\"_\")[0]) * cpu_cores_multipler\n",
    "        cpu = int(powermode.split(\"_\")[1]) / cpu_frq_divider\n",
    "        gpu = int(powermode.split(\"_\")[2]) / gpu_frq_divider\n",
    "        mem = int(powermode.split(\"_\")[3]) / mem_frq_divider\n",
    "\n",
    "        temp_df = pd.read_csv(file, header=None)\n",
    "        # temp_df = temp_df[temp_df[4].replace('.', '', 1).astype(str).str.isnumeric()]\n",
    "        # temp_df = temp_df[temp_df[4].apply(is_numeric_value)]\n",
    "        # print(temp_df.head())\n",
    "\n",
    "        if offset == -1:\n",
    "            start = len(temp_df) - 40\n",
    "            end = len(temp_df)\n",
    "        elif offset == 0:\n",
    "            start = offset + 1\n",
    "            end = start + 40\n",
    "        else:\n",
    "            start = offset\n",
    "            end = start + 40\n",
    "\n",
    "        diff = end-start\n",
    "        if len(temp_df[start:end]) != 40:\n",
    "            print(\"Diff :\", diff)\n",
    "            print(\"Start :\",start)\n",
    "            print(\"End:\",end)\n",
    "            print(\"Offset: \",offset)\n",
    "            print(\"Powermode :\",powermode)\n",
    "            print(\"Length :\",len(temp_df))\n",
    "\n",
    "        temp_df = temp_df.iloc[start:end]\n",
    "        # Changed from 4 to 5 for yolo\n",
    "        temp_df = temp_df.iloc[:,4]\n",
    "        temp_df = temp_df.to_frame() \n",
    "        # print(temp_df.head())\n",
    "        temp_df['Cores'] = cores\n",
    "        temp_df['CPU_frequency'] = cpu\n",
    "        temp_df['GPU_frequency'] = gpu\n",
    "        temp_df['Memory_frequency'] = mem\n",
    "        temp_df.columns = ['Minibatch_time', 'Cores', 'CPU_frequency', 'GPU_frequency', 'Memory_frequency']\n",
    "        # print(temp_df.head())\n",
    "\n",
    "        all_data.append(temp_df)\n",
    "\n",
    "    master_df = pd.concat(all_data, ignore_index=True)\n",
    "    return master_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_data_power(sampled_powermodes, path, tg_filename, offset_dict, start_dict, end_dict):\n",
    "\n",
    "    rows = []\n",
    "    for powermode in sampled_powermodes:\n",
    "        offset = offset_dict.get(powermode, -1)\n",
    "        start_time = start_dict.get(powermode, -1)\n",
    "        end_time = end_dict.get(powermode, -1)\n",
    "\n",
    "        if end_time - start_time == 0:\n",
    "            end_time = end_time + 2\n",
    "            start_time = start_time - 2\n",
    "            print(\"End time is less than start time\")\n",
    "        # file = path + \"/\" + \"pm_\" + powermode + \"/\" + filename\n",
    "        tg_file = path + \"/\" + \"pm_\" + powermode + \"/\" + tg_filename\n",
    "        # print(start_time)\n",
    "        tg_df = pd.read_csv(tg_file)\n",
    "        # print(tg_file)\n",
    "        filtered_df = tg_df[(tg_df['log_time'] >= start_time) & (tg_df['log_time'] <= end_time)]\n",
    "        # print(filtered_df)\n",
    "        power_list = filtered_df['power cur'].astype(float).dropna().tolist()\n",
    "        # print(powermode)\n",
    "        # print(power_list)\n",
    "        #Resnet: 22\n",
    "        #Mobnet: 40\n",
    "        #Yolo: 100\n",
    "        required_length = 500\n",
    "        if len(power_list) < required_length:\n",
    "            repeats_required = -(-required_length // len(power_list))  \n",
    "            power_list = (power_list * repeats_required)[:required_length]\n",
    "\n",
    "        power_list = power_list[:required_length]\n",
    "\n",
    "        # Split the powermode into its components\n",
    "        cores, cpu, gpu, mem = powermode.split(\"_\")\n",
    "\n",
    "        for sample in power_list:\n",
    "            rows.append({\n",
    "                'cores': cores,\n",
    "                'cpu': cpu,\n",
    "                'gpu': gpu,\n",
    "                'mem': mem,\n",
    "                'power_sample': sample\n",
    "            })\n",
    "\n",
    "    minibatch_power_df = pd.DataFrame(rows)\n",
    "    # minibatch_power_df.to_csv(\"val_power.csv\", index=False)\n",
    "    return minibatch_power_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_offsets_from_csv(csv_file):\n",
    "    df = pd.read_csv(csv_file) \n",
    "    powermode_offsets = {}\n",
    "    start_times = {}\n",
    "    end_times = {}\n",
    "    # Iterate through the DataFrame and populate the dictionary\n",
    "    for _, row in df.iterrows():\n",
    "        powermode = f\"{int(row['cores'])}_{int(row['cpu'])}_{int(row['gpu'])}_{int(row['mem'])}\"\n",
    "        offset = int(row['skip_index'])\n",
    "        start_time = float(row['start_time'])\n",
    "        end_time = float(row['end_time'])\n",
    "        powermode_offsets[powermode] = offset\n",
    "        start_times[powermode] = start_time\n",
    "        end_times[powermode] = end_time\n",
    "    return powermode_offsets, start_times, end_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_powermodes():\n",
    "    core_vals=[4, 8, 12] #3 possible values\n",
    "    gpu_vals=[114750000, 318750000, 522750000, 726750000, 930750000, 1134750000, 1300500000]\n",
    "    cpu_vals=[422400, 729600, 1036800, 1344000, 1651200, 1958400, 2201600] #in kHz, 7 possible values\n",
    "    mem_vals = [665600000, 2133000000, 3199000000]\n",
    "    #get combinations of all 4 as powermode Ex.2_1300500000_268800_204000000\n",
    "    all_powermodes=[] #6*13*14*4=4368 possible values\n",
    "    for cpu_frequency in cpu_vals:\n",
    "        for gpu_frequency in gpu_vals:\n",
    "            for cpu_core in core_vals:\n",
    "                for mem_frequency in mem_vals:\n",
    "                    all_powermodes.append(str(cpu_core)+\"_\"+str(cpu_frequency)+\"_\"+str(gpu_frequency)+\"_\"+str(mem_frequency))\n",
    "\n",
    "\n",
    "    return all_powermodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_powermodes = generate_powermodes()\n",
    "\n",
    "path = '/home/saisamarth/exp/training_bs16_runs/LSTM'\n",
    "time_filename = 'mn_nw4_pf2_epoch_stats.csv'\n",
    "power_filename = 'mn_nw4_pf2_tegrastats.csv'\n",
    "offset_file = '/home/saisamarth/exp/AALSTM.csv'\n",
    "offsets, start_times, end_times = extract_offsets_from_csv(offset_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_time = []\n",
    "val_power = []\n",
    "for powermode in all_powermodes:\n",
    "    val_time.append(populate_data_time([powermode], path, time_filename, offsets))\n",
    "    val_power.append(populate_data_power([powermode], path, power_filename, offsets, start_times, end_times))\n",
    "time_df = pd.concat(val_time, ignore_index=True)\n",
    "power_df = pd.concat(val_power, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 220500 entries, 0 to 220499\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   cores         220500 non-null  object \n",
      " 1   cpu           220500 non-null  object \n",
      " 2   gpu           220500 non-null  object \n",
      " 3   mem           220500 non-null  object \n",
      " 4   power_sample  220500 non-null  float64\n",
      "dtypes: float64(1), object(4)\n",
      "memory usage: 8.4+ MB\n"
     ]
    }
   ],
   "source": [
    "power_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_df['Minibatch_time'] = time_df['Minibatch_time'].astype(float)\n",
    "power_df['cores'] = power_df['cores'].astype(int)\n",
    "power_df['cpu'] = power_df['cpu'].astype(int)\n",
    "power_df['gpu'] = power_df['gpu'].astype(int)\n",
    "power_df['mem'] = power_df['mem'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take median of every 40 sample for time df and 500 samples for power df\n",
    "time_df = time_df.groupby(time_df.index // 40).apply(lambda x: x.median())\n",
    "power_df = power_df.groupby(power_df.index // 500).apply(lambda x: x.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_df = time_df[['Cores', 'CPU_frequency', 'GPU_frequency', 'Memory_frequency', 'Minibatch_time']]\n",
    "time_df.columns = ['cores', 'cpu', 'gpu', 'mem', 'observed_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_df.columns = ['cores', 'cpu', 'gpu', 'mem', 'observed_power']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged both the dataframes on cores, cpu, gpu, mem\n",
    "merged_df = pd.merge(time_df, power_df, on=['cores', 'cpu', 'gpu', 'mem'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['cores'] = merged_df['cores'].astype(int)\n",
    "merged_df['cpu'] = merged_df['cpu'].astype(int)\n",
    "merged_df['gpu'] = merged_df['gpu'].astype(int)\n",
    "merged_df['mem'] = merged_df['mem'].astype(int)\n",
    "\n",
    "merged_df['observed_power'] = merged_df['observed_power']/1000.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv(\"lstm_train_data_final.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
