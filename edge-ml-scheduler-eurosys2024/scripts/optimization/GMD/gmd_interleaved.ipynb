{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 757,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 758,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6885\n"
     ]
    }
   ],
   "source": [
    "model_train = 'yolo'\n",
    "model_infer = 'resnet'\n",
    " \n",
    "model_train = 'resnet'\n",
    "model_infer = 'mobnet'\n",
    " \n",
    "model_train = 'mobnet'\n",
    "model_infer = 'lstm'\n",
    " \n",
    "model_train = 'mobnet'\n",
    "model_infer = 'mobnet'\n",
    " \n",
    "model_train = 'resnet'\n",
    "model_infer = 'bert'\n",
    "\n",
    "# arr_rate = 60\n",
    "# arr_rate_list, from 30 to 120 in 5 increments\n",
    "\n",
    "# time_list, from 0.5 to 2 in 0.1 increments\n",
    "\n",
    "arr_rate_list = [30, 40, 50, 60, 70, 80, 90, 100, 110, 120]\n",
    "time_list = [0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 2.0]\n",
    "power_list = np.arange(10, 51, 1)\n",
    "\n",
    "if model_infer == 'bert' or model_train == 'bert':\n",
    "\n",
    "    time_list = [2, 2.5, 3, 3.5, 4, 4.5, 5, 5.5, 6]\n",
    "    arr_rate_list = [1,2,3,4,5,6,7,8,9,10, 11, 12, 13, 14, 15]\n",
    "    power_list = np.arange(10, 61, 1)\n",
    "    print(len(arr_rate_list)*len(time_list)*len(power_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 759,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(f'{model_train}_train_data_final.csv')\n",
    "data_infer = pd.read_csv(f'{model_infer}_infer_data_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 760,
   "metadata": {},
   "outputs": [],
   "source": [
    "core_vals=[4, 8, 12] #3 possible values\n",
    "gpu_vals=[114750000, 318750000, 522750000, 726750000, 930750000, 1134750000, 1300500000]\n",
    "cpu_vals=[422400, 729600, 1036800, 1344000, 1651200, 1958400, 2201600] #in kHz, 7 possible values\n",
    "mem_vals = [665600000, 2133000000, 3199000000]\n",
    "bs_vals = [1, 4, 16, 32, 64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 761,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Filter data based on values in the list only\n",
    "data_train = data_train[data_train['cores'].isin(core_vals)]\n",
    "data_train = data_train[data_train['gpu'].isin(gpu_vals)]\n",
    "data_train = data_train[data_train['cpu'].isin(cpu_vals)]\n",
    "data_train = data_train[data_train['mem'].isin(mem_vals)]\n",
    "data_train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 762,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_initial_samples(data, power_budget):\n",
    "    mid_cores = int(np.median(core_vals))\n",
    "    mid_gpu = int(np.median(gpu_vals))\n",
    "    mid_cpu = int(np.median(cpu_vals))\n",
    "    mid_mem = int(np.median(mem_vals))\n",
    "\n",
    "    index_list = []\n",
    "\n",
    "    # Extarct the sample with mid values\n",
    "    mid_sample = data[(data['cores'] == mid_cores) & (data['gpu'] == mid_gpu) & (data['cpu'] == mid_cpu) & (data['mem'] == mid_mem)]\n",
    "    # Extract the index of the sample\n",
    "    mid_index = mid_sample.index[0]\n",
    "    index_list.append(mid_index)\n",
    "    mid_power = mid_sample['interleaved_power'].values[0]\n",
    "\n",
    "    if mid_power > power_budget:\n",
    "        new_cores = int(min(core_vals))\n",
    "        new_gpu = int(min(gpu_vals))\n",
    "        new_cpu = int(min(cpu_vals))\n",
    "        new_mem = int(min(mem_vals))\n",
    "\n",
    "        sample1 = data[(data['cores'] == new_cores) & (data['gpu'] == mid_gpu) & (data['cpu'] == mid_cpu) & (data['mem'] == mid_mem)]\n",
    "        sample2 = data[(data['cores'] == mid_cores) & (data['gpu'] == new_gpu) & (data['cpu'] == mid_cpu) & (data['mem'] == mid_mem)]\n",
    "        sample3 = data[(data['cores'] == mid_cores) & (data['gpu'] == mid_gpu) & (data['cpu'] == new_cpu) & (data['mem'] == mid_mem)]\n",
    "        sample4 = data[(data['cores'] == mid_cores) & (data['gpu'] == mid_gpu) & (data['cpu'] == mid_cpu) & (data['mem'] == new_mem)]\n",
    "\n",
    "        index_list.append(sample1.index[0])\n",
    "        index_list.append(sample2.index[0])\n",
    "        index_list.append(sample3.index[0])\n",
    "        index_list.append(sample4.index[0])\n",
    "\n",
    "        pair1 = index_list[0:2]\n",
    "        pair2 = index_list[0:1] + index_list[2:3]\n",
    "        pair3 = index_list[0:1] + index_list[3:4]\n",
    "        pair4 = index_list[0:1] + index_list[4:5]\n",
    "\n",
    "        pairs = [pair1, pair2, pair3, pair4]\n",
    "    \n",
    "    else:\n",
    "        new_cores = int(max(core_vals))\n",
    "        new_gpu = int(max(gpu_vals))\n",
    "        new_cpu = int(max(cpu_vals))\n",
    "        new_mem = int(max(mem_vals))\n",
    "\n",
    "        sample1 = data[(data['cores'] == new_cores) & (data['gpu'] == mid_gpu) & (data['cpu'] == mid_cpu) & (data['mem'] == mid_mem)]\n",
    "        sample2 = data[(data['cores'] == mid_cores) & (data['gpu'] == new_gpu) & (data['cpu'] == mid_cpu) & (data['mem'] == mid_mem)]\n",
    "        sample3 = data[(data['cores'] == mid_cores) & (data['gpu'] == mid_gpu) & (data['cpu'] == new_cpu) & (data['mem'] == mid_mem)]\n",
    "        sample4 = data[(data['cores'] == mid_cores) & (data['gpu'] == mid_gpu) & (data['cpu'] == mid_cpu) & (data['mem'] == new_mem)]\n",
    "\n",
    "        index_list.append(sample1.index[0])\n",
    "        index_list.append(sample2.index[0])\n",
    "        index_list.append(sample3.index[0])\n",
    "        index_list.append(sample4.index[0])\n",
    "\n",
    "        pair1 = index_list[0:2]\n",
    "        pair2 = index_list[0:1] + index_list[2:3]\n",
    "        pair3 = index_list[0:1] + index_list[3:4]\n",
    "        pair4 = index_list[0:1] + index_list[4:5]\n",
    "\n",
    "        pairs = [pair1, pair2, pair3, pair4]\n",
    "\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 763,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_lines(data, pairs, zero_list, dom):\n",
    "\n",
    "    # if dom == 'train':\n",
    "    #     print(\"Train Slope Calculation\")\n",
    "    # else:\n",
    "    #     print(\"Infer Slope Calculation\")\n",
    "\n",
    "    flag = False\n",
    "    mode = ['cores', 'gpu','cpu','mem']\n",
    "    slopes = []\n",
    "\n",
    "    \n",
    "    for i in range(len(pairs)):\n",
    "        # Fit a time and power line for each pair\n",
    "        sample1 = data.iloc[pairs[i][0]]\n",
    "        sample2 = data.iloc[pairs[i][1]]\n",
    "        \n",
    "        sample1['cores'] = sample1['cores']*100\n",
    "        sample1['cpu'] = sample1['cpu']/1000\n",
    "        sample1['mem'] = sample1['mem']/1000000\n",
    "        sample1['gpu'] = sample1['gpu']/1000000\n",
    "\n",
    "        sample2['cores'] = sample2['cores']*100\n",
    "        sample2['cpu'] = sample2['cpu']/1000\n",
    "        sample2['mem'] = sample2['mem']/1000000\n",
    "        sample2['gpu'] = sample2['gpu']/1000000\n",
    "        # print(sample1)\n",
    "        # print(sample2)\n",
    "\n",
    "        x1 = sample1[mode[i]]\n",
    "        x2 = sample2[mode[i]]\n",
    "\n",
    "        if dom == 'train':\n",
    "            yt1 = sample1['observed_time_train']\n",
    "            yt2 = sample2['observed_time_train']\n",
    "\n",
    "            yp1 = sample1['observed_power_train']\n",
    "            yp2 = sample2['observed_power_train']\n",
    "\n",
    "        else:\n",
    "            yt1 = sample1['observed_time_infer']\n",
    "            yt2 = sample2['observed_time_infer']\n",
    "\n",
    "            yp1 = sample1['observed_power_infer']\n",
    "            yp2 = sample2['observed_power_infer']\n",
    "        \n",
    "        m_time = (yt2 - yt1)/(x2 - x1)\n",
    "        # c_time = yt1 - m_time*x1\n",
    "\n",
    "        m_power = (yp2 - yp1)/(x2 - x1)\n",
    "        # c_power = yp1 - m_power*x1\n",
    "\n",
    "        slope = m_time/m_power\n",
    "\n",
    "        if abs(yp2 - yp1) < 1:\n",
    "            slope = 0\n",
    "            # print(\"Power under 1W for mode {dim}, setting slope to 0\".format(dim=mode[i]))\n",
    "        # print(\"Mode : \", mode[i])\n",
    "        # m_time_formated = \"{:.3f}\".format(m_time)\n",
    "        # c_time_formated = \"{:.3f}\".format(c_time)\n",
    "        # m_power_formated = \"{:.3f}\".format(m_power)\n",
    "        # c_power_formated = \"{:.3f}\".format(c_power)\n",
    "        # print(f\"Time Line: y = {m_time_formated}x + {c_time_formated}\")\n",
    "        # print(f\"Power Line: y = {m_power_formated}x + {c_power_formated}\")\n",
    "        # print(\"B/A =\",\"{:.3f}\".format( m_time/m_power))\n",
    "        slopes.append(slope)\n",
    "        # print(\"\\n\")\n",
    "    \n",
    "\n",
    "    slopes = [abs(x) for x in slopes]\n",
    "    # change any value greater than 100 to 0 in slopes list\n",
    "\n",
    "    zero_index = [mode.index(x) for x in zero_list]\n",
    "\n",
    "    for i in zero_index:\n",
    "        slopes[i] = 0\n",
    "\n",
    "    # round the slopes to 2 decimal places\n",
    "    slopes_print = [round(x, 2) for x in slopes]\n",
    "    # print(\"Slopes (Cores, GPU, CPU, Memory): \", slopes_print)\n",
    "    if sum(slopes) == 0:\n",
    "        flag = True\n",
    "    # return the index of the minimum value in the slopes list\n",
    "    max_index = slopes.index(max(slopes))\n",
    "    max_dim = mode[max_index]\n",
    "    \n",
    "    return max_index, max_dim, flag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 764,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_search(core_vals, cpu_vals, gpu_vals, mem_vals, dim, step, cores, cpu, gpu, mem):\n",
    "    # Using binary search to find the optimal value for the dimension\n",
    "\n",
    "    \n",
    "    if dim == 'cores':\n",
    "        vals = core_vals\n",
    "        value = cores\n",
    "    elif dim == 'cpu':\n",
    "        vals = cpu_vals\n",
    "        value = cpu\n",
    "    elif dim == 'gpu':\n",
    "        vals = gpu_vals\n",
    "        value = gpu\n",
    "    else:\n",
    "        vals = mem_vals\n",
    "        value = mem\n",
    "\n",
    "    if step=='next':    \n",
    "        # print(\"Mode: Next\")\n",
    "        dim_index = vals.index(value)\n",
    "        # print(\"Dim Index: \", dim_index)\n",
    "        last_index = len(vals)-1\n",
    "        # print(\"Last Index: \", last_index)\n",
    "        new_index = int(np.ceil((dim_index + last_index)/2))\n",
    "        value = vals[new_index]\n",
    "        vals = vals[dim_index+1:]\n",
    "\n",
    "\n",
    "    else:\n",
    "        # print(\"Mode: Prev\")\n",
    "        dim_index = vals.index(value)\n",
    "        new_index = int(np.floor(dim_index/2))\n",
    "        value = vals[new_index]\n",
    "        vals = vals[:dim_index]\n",
    "\n",
    "    return value, vals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 765,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(data_train, data_infer, power_budget, max_count, start_bs):\n",
    "\n",
    "    index_list = []\n",
    "\n",
    "    zero_list = []\n",
    "\n",
    "    visited_dim = []\n",
    "\n",
    "    core_vals=[4, 8, 12] #3 possible values\n",
    "    gpu_vals=[114750000, 318750000, 522750000, 726750000, 930750000, 1134750000, 1300500000]\n",
    "    cpu_vals=[422400, 729600, 1036800, 1344000, 1651200, 1958400, 2201600] #in kHz, 7 possible values\n",
    "    mem_vals = [665600000, 2133000000, 3199000000]\n",
    "    bs_vals = [1, 4, 16, 32, 64]\n",
    "\n",
    "    data_infer = data_infer[data_infer['bs'] == start_bs]\n",
    "    data_infer.reset_index(drop=True, inplace=True)\n",
    "    data_train.reset_index(drop=True, inplace=True)\n",
    "    # merge the data_train and data_infer based on cores, gpu, cpu, mem with suffixes _train and _infer\n",
    "    data = pd.merge(data_train, data_infer, on=['cores', 'gpu', 'cpu', 'mem'], suffixes=('_train', '_infer'))\n",
    "    data['interleaved_power'] = np.maximum(data['observed_power_train'], data['observed_power_infer'])\n",
    "    data['interleaved_time'] = data['observed_time_train'] + data['observed_time_infer']\n",
    "    \n",
    "    pairs = return_initial_samples(data, power_budget)\n",
    "\n",
    "    for i in pairs:\n",
    "        index_list.append(i[0])\n",
    "        index_list.append(i[1])\n",
    "\n",
    "    # print(\"Initial Pairs: \", pairs)\n",
    "\n",
    "    mid_index = index_list[0]\n",
    "\n",
    "    # # print(\"Initial Index: \", mid_index)\n",
    "    mid_power_train = data.iloc[mid_index]['observed_power_train']\n",
    "    mid_power_infer = data.iloc[mid_index]['observed_power_infer']\n",
    "\n",
    "    curr_power_train = mid_power_train\n",
    "    curr_power_infer = mid_power_infer\n",
    "\n",
    "    # print(\"Initial Train Power: \", mid_power_train)\n",
    "    # print(\"Initial Infer Power: \", mid_power_infer)\n",
    "    # print(\"\\n\")\n",
    "\n",
    "    count = 1\n",
    "    while count < max_count:\n",
    "\n",
    "        if curr_power_train > curr_power_infer:\n",
    "            max_index, max_dim, flag = fit_lines(data, pairs, zero_list, 'train')\n",
    "        else:\n",
    "            max_index, max_dim, flag = fit_lines(data, pairs, zero_list, 'infer')\n",
    "        \n",
    "        # print(\"Dimension with max slope: \", max_dim)\n",
    "        visited_dim.append(max_dim)\n",
    "\n",
    "        if flag:\n",
    "            break\n",
    "\n",
    "        next_pair = pairs[max_index]\n",
    "\n",
    "        if count == 1:\n",
    "            curr_sample = data.iloc[next_pair[0]]\n",
    "            curr_cores = curr_sample['cores']\n",
    "            curr_cpu = curr_sample['cpu']\n",
    "            curr_gpu = curr_sample['gpu']\n",
    "            curr_mem = curr_sample['mem']\n",
    "            curr_power_train = curr_sample['observed_power_train']\n",
    "            curr_power_infer = curr_sample['observed_power_infer']\n",
    "            \n",
    "        interleaved_power = np.maximum(curr_power_train, curr_power_infer)\n",
    "\n",
    "\n",
    "\n",
    "        if interleaved_power < power_budget:\n",
    "            value, vals = bin_search(core_vals, cpu_vals, gpu_vals, mem_vals, max_dim, 'next', curr_cores, curr_cpu, curr_gpu, curr_mem)\n",
    "            # print(\"New Dim value: \", value)\n",
    "            # print(\"Updated dim list: \", vals)\n",
    "            if len(vals) == 1:\n",
    "                zero_list.append(max_dim)\n",
    "                # print(\"Setting slope of {dim} to 0\".format(dim=max_dim))\n",
    "\n",
    "            if max_dim == 'cores':\n",
    "                curr_cores = value\n",
    "                core_vals = vals\n",
    "            elif max_dim == 'cpu':\n",
    "                curr_cpu = value\n",
    "                cpu_vals = vals\n",
    "            elif max_dim == 'gpu':\n",
    "                curr_gpu = value\n",
    "                gpu_vals = vals\n",
    "            else:\n",
    "                curr_mem = value\n",
    "                mem_vals = vals\n",
    "\n",
    "        else:\n",
    "            value, vals = bin_search(core_vals, cpu_vals, gpu_vals, mem_vals, max_dim, 'prev', curr_cores, curr_cpu, curr_gpu, curr_mem)\n",
    "            # print(\"New Dim value: \", value)\n",
    "            # print(\"Updated dim list: \", vals)\n",
    "            if len(vals) == 1:\n",
    "                zero_list.append(max_dim)\n",
    "                # print(\"Setting slope of {dim} to 0\".format(dim=max_dim))\n",
    "\n",
    "            if max_dim == 'cores':\n",
    "                curr_cores = value\n",
    "                core_vals = vals\n",
    "            elif max_dim == 'cpu':\n",
    "                curr_cpu = value\n",
    "                cpu_vals = vals\n",
    "            elif max_dim == 'gpu':\n",
    "                curr_gpu = value\n",
    "                gpu_vals = vals\n",
    "            else:\n",
    "                curr_mem = value\n",
    "                mem_vals = vals\n",
    "\n",
    "        # retrive new index from data\n",
    "        new_sample = data[(data['cores'] == int(curr_cores)) & (data['gpu'] == int(curr_gpu)) & (data['cpu'] == int(curr_cpu)) & (data['mem'] == int(curr_mem))]\n",
    "        curr_power_train = new_sample['observed_power_train'].values[0]\n",
    "        curr_power_infer = new_sample['observed_power_infer'].values[0]\n",
    "        new_index = new_sample.index[0]\n",
    "        index_list.append(new_index)\n",
    "        # print(\"New Index at \"+str(count)+\" iteration: \",new_index)\n",
    "\n",
    "\n",
    "        if interleaved_power < power_budget:\n",
    "            pairs[max_index] = [next_pair[0], new_index]\n",
    "        else:\n",
    "            pairs[max_index] = [new_index, next_pair[1]]\n",
    "\n",
    "        # print(\"Pairs at \"+str(count)+\" iteration: \",pairs) \n",
    "        # divide the curr_cpu by 1000, curr_mem by 1000000 and curr_gpu by 1000000\n",
    "        curr_cpu_print = curr_cpu/1000\n",
    "        curr_gpu_print = curr_gpu/1000000\n",
    "        curr_mem_print = curr_mem/1000000\n",
    "        # print(\"Current Cores, CPU, GPU, Memory at \"+str(count)+\" iteration: \",curr_cores, curr_cpu_print, curr_gpu_print, curr_mem_print)\n",
    "\n",
    "        # print(\"Train Power at \"+str(count)+\" iteration: \",curr_power_train)\n",
    "        # print(\"Infer Power at \"+str(count)+\" iteration: \",curr_power_infer)\n",
    "\n",
    "        # print(\"\\n\")\n",
    "        count+=1\n",
    "\n",
    "    visited_dim = list(set(visited_dim))\n",
    "\n",
    "    return data.iloc[index_list], len(set(index_list)), visited_dim   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "metadata": {},
   "outputs": [],
   "source": [
    "# algo_sol_df, tries, _ = main(data_train, data_infer, 11, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prev_bs_picker(data, curr_bs, power_budget, time_budget, data_all, tries):\n",
    "\n",
    "    data['cond3'] = np.where(data['time_cond2'] < curr_bs, 1, 0)    \n",
    "    data = data[data['cond3'] == 1]\n",
    "    data.sort_values(by=['observed_time_infer'], ascending=True, inplace=True)\n",
    "    powermodes = list(data['powermode'].values)\n",
    "    # powermodes = list(set(powermodes))\n",
    "    \n",
    "    # filter data_all based on powermodes\n",
    "    # data_all = data_all[data_all['powermode'].isin(powermodes)]\n",
    "    # filter data_all, remove all bs greater than or equal to curr_bs\n",
    "    data_all = data_all[data_all['bs'] < curr_bs] \n",
    "    # cond 1 columns is 1 if interleaved_power is <= power_budget else 0\n",
    "    data_all['cond1'] = np.where(data_all['interleaved_power'] <= power_budget, 1, 0)   \n",
    "    # cond2 column is 1 if time_cond1 is <= time_budget else 0\n",
    "    data_all['cond2'] = np.where(data_all['time_cond1'] <= time_budget, 1, 0)\n",
    "    # cond3 column is 1 if time_cond2 is <= bs else 0\n",
    "    data_all['cond3'] = np.where(data_all['time_cond2'] <= data_all['bs'], 1, 0)\n",
    "    \n",
    "    # data_all = data_all[data_all['cond3'] == 1]\n",
    "    # print(data_all)\n",
    "\n",
    "    avail_bs = list(data_all['bs'].values)\n",
    "    # sort the bs values in desc order\n",
    "    avail_bs = list(set(avail_bs))\n",
    "    avail_bs.sort(reverse=True)\n",
    "    # print(\"Available BS values: \", avail_bs)\n",
    "\n",
    "    visted_data = pd.DataFrame(columns=data_all.columns)\n",
    "\n",
    "    i = 1\n",
    "    for bs in avail_bs:\n",
    "        for powermode in powermodes:\n",
    "            # get the data for the current bs and powermode\n",
    "            curr_sample = data_all[(data_all['bs'] == bs) & (data_all['powermode'] == str(powermode))]\n",
    "            # add the current sample to the visited data\n",
    "            visted_data = pd.concat([visted_data, curr_sample])\n",
    "            if curr_sample.empty:\n",
    "                # print(\"No data found for BS: \", bs, \" Powermode: \", powermode)\n",
    "                continue\n",
    "            else:\n",
    "\n",
    "                if curr_sample['cond1'].values[0] == 1 and curr_sample['cond2'].values[0] == 1 and curr_sample['cond3'].values[0] == 1:\n",
    "                    # print(\"Solution found at iteration: \", i)\n",
    "                    # print(\"BS: \", bs)\n",
    "                    # print(\"Powermode: \", powermode)\n",
    "                    # print(\"Time Cond1: \", curr_sample['time_cond1'].values[0])\n",
    "                    # print(\"Time Cond2: \", curr_sample['time_cond2'].values[0])\n",
    "                    # print(\"Interleaved Power: \", curr_sample['interleaved_power'].values[0])\n",
    "                    # print(\"\\n\")\n",
    "                    return curr_sample, tries, data_all, data\n",
    "                \n",
    "            if tries == 25:\n",
    "                break\n",
    "            i+=1\n",
    "            tries+=1\n",
    "    \n",
    "    # print(\"No solution found\")\n",
    "    # return empty dataframe\n",
    "    return pd.DataFrame(), tries, data_all, data\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_sol_df, tries, _ = main(data_train, data_infer, 20, 15, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 769,
   "metadata": {},
   "outputs": [],
   "source": [
    "# algo_sol_df = helper(algo_sol_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 770,
   "metadata": {},
   "outputs": [],
   "source": [
    "# algo_sol_df.drop_duplicates(inplace=True)\n",
    "# algo_sol_df.sort_values(by=['observed_time_infer'], inplace=True)\n",
    "# algo_sol_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "metadata": {},
   "outputs": [],
   "source": [
    "# powermodes = list(algo_sol_df['powermode'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "metadata": {},
   "outputs": [],
   "source": [
    "# powermodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "metadata": {},
   "outputs": [],
   "source": [
    "# curr_bs = algo_sol_df.iloc[0]['bs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 774,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # merge the data_train and data_infer based on cores, gpu, cpu, mem with suffixes _train and _infer\n",
    "# data_all = pd.merge(data_train, data_infer, on=['cores', 'gpu', 'cpu', 'mem'], suffixes=('_train', '_infer'))\n",
    "# data_all = helper(data_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 775,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _, _, data_sample, data = prev_bs_picker(algo_sol_df, curr_bs, 20, 1, data_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 776,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 777,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 778,
   "metadata": {},
   "outputs": [],
   "source": [
    "def helper(data, arr_rate):\n",
    "    data['interleaved_power'] = np.maximum(data['observed_power_train'], data['observed_power_infer'])\n",
    "    data['interleaved_time'] = data['observed_time_train'] + data['observed_time_infer']\n",
    "    data['powermode'] = data['cores'].astype(str) + \"_\" + data['cpu'].astype(str) + \"_\" + data['gpu'].astype(str) + \"_\" + data['mem'].astype(str)\n",
    "    data['observed_time_infer_scaled'] = data['observed_time_infer']/1000\n",
    "    data['observed_time_train_scaled'] = data['observed_time_train']/1000\n",
    "    data['num_train_batches'] = np.floor(((data['bs'].astype(int))/arr_rate - data['observed_time_infer_scaled'])/data['observed_time_train_scaled']).astype(int)\n",
    "    data['time_cond1'] = (data['bs'].astype(int))/arr_rate + data['observed_time_infer_scaled']\n",
    "    data['time_cond2'] = data['observed_time_infer_scaled']*arr_rate\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_row_optim_algo(data, time_budget, power_budget, data_all, tries):\n",
    "\n",
    "    data_cond = data[data['interleaved_power'] <= power_budget]\n",
    "    data_cond = data_cond[data_cond['time_cond1'] <= time_budget]\n",
    "    data_cond = data_cond[data_cond['time_cond2'] <= data_cond['bs']]\n",
    "    # print(\"Data Cond: \", data_cond)\n",
    "\n",
    "    curr_bs = data.iloc[0]['bs']\n",
    "\n",
    "    if data_cond.empty:\n",
    "        # print(\"No solution found in current data, backtracking\")\n",
    "        sol, new_tries, _, _ = prev_bs_picker(data, curr_bs, power_budget, time_budget, data_all, tries)\n",
    "        # print(sol)\n",
    "        if sol.empty:\n",
    "            return None, None, None, None, None, None, new_tries\n",
    "        else:\n",
    "            return sol['powermode'].values[0], sol['bs'].values[0], sol['interleaved_power'].values[0], sol['observed_time_infer'].values[0], sol['observed_time_train'].values[0], sol['num_train_batches'].values[0], new_tries\n",
    "           \n",
    "    else:   \n",
    "        # print(\"Solution found in current data\")  \n",
    "        data_cond = data_cond.sort_values(by=['num_train_batches'],ascending=False)\n",
    "\n",
    "        train_batch_vals = data_cond['num_train_batches'].unique()\n",
    "        max_train_batch_val = max(train_batch_vals)\n",
    "\n",
    "        data_cond = data_cond[data_cond['num_train_batches'] == max_train_batch_val]\n",
    "        data_cond.sort_values(by=['observed_time_infer_scaled'], inplace=True)\n",
    "\n",
    "        data_cond = data_cond.iloc[0]\n",
    "        powermode = data_cond['powermode']\n",
    "        bs = data_cond['bs']\n",
    "        power = data_cond['interleaved_power']\n",
    "        infer_time = data_cond['observed_time_infer']\n",
    "        train_time = data_cond['observed_time_train']\n",
    "        num_train_batches = data_cond['num_train_batches']\n",
    "        tries = tries\n",
    "\n",
    "        return powermode, bs, power, infer_time, train_time, num_train_batches, tries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 780,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_row_optim(data, time_budget, power_budget):\n",
    "\n",
    "    data = data[data['interleaved_power'] <= power_budget]\n",
    "    data = data[data['time_cond1'] <= time_budget]\n",
    "    data = data[data['time_cond2'] <= data['bs']]\n",
    "\n",
    "\n",
    "    if data.empty:\n",
    "        return None, None, None, None, None, None, 1\n",
    "    \n",
    "    else:     \n",
    "        data = data.sort_values(by=['num_train_batches'],ascending=False)\n",
    "\n",
    "        train_batch_vals = data['num_train_batches'].unique()\n",
    "        max_train_batch_val = max(train_batch_vals)\n",
    "\n",
    "        data = data[data['num_train_batches'] == max_train_batch_val]\n",
    "        data.sort_values(by=['observed_time_infer_scaled'], inplace=True)\n",
    "\n",
    "        data = data.iloc[0]\n",
    "        powermode = data['powermode']\n",
    "        bs = data['bs']\n",
    "        power = data['interleaved_power']\n",
    "        infer_time = data['observed_time_infer']\n",
    "        train_time = data['observed_time_train']\n",
    "        num_train_batches = data['num_train_batches']\n",
    "\n",
    "        return powermode, bs, power, infer_time, train_time, num_train_batches, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# power_list = [15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "metadata": {},
   "outputs": [],
   "source": [
    "# algo_sol_df, tries, _ = main(data_train, data_infer, power_budget, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 783,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_bs(data_all, time_budget):\n",
    "    \n",
    "    maxn = data_all[data_all['powermode']=='12_2201600_1300500000_3199000000']\n",
    "    maxn = maxn[maxn['time_cond1'] <= time_budget]\n",
    "    maxn = maxn[maxn['time_cond2'] <= maxn['bs']]\n",
    "\n",
    "    maxn_bs = list(maxn['bs'].values)\n",
    "    # return the maximum bs value\n",
    "    return max(maxn_bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 784,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_num_tries = {1: 5, 4: 4, 8:4, 16:3, 32:2, 64:1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arr Rate:  1\n",
      "Arr Rate:  2\n",
      "Arr Rate:  3\n",
      "Arr Rate:  4\n",
      "Arr Rate:  5\n",
      "Arr Rate:  6\n",
      "Arr Rate:  7\n",
      "Arr Rate:  8\n",
      "Arr Rate:  9\n",
      "Arr Rate:  10\n",
      "Arr Rate:  11\n",
      "Arr Rate:  12\n",
      "Arr Rate:  13\n",
      "Arr Rate:  14\n",
      "Arr Rate:  15\n"
     ]
    }
   ],
   "source": [
    "algo_df = pd.DataFrame(columns=['powermode','infer_time','bs','interleaved_power','power_budget','num_train_batches','num_tries', 'time_budget', 'arr_rate'])\n",
    "\n",
    "# power_list = [20]\n",
    "for arr_rate in arr_rate_list:\n",
    "    for time_budget in time_list:\n",
    "        for power_budget in power_list:\n",
    "            # print(\"Power Budget: \", power_budget)\n",
    "            # merge the data_train and data_infer based on cores, gpu, cpu, mem with suffixes _train and _infer\n",
    "            data_all = pd.merge(data_train, data_infer, on=['cores', 'gpu', 'cpu', 'mem'], suffixes=('_train', '_infer'))\n",
    "            data_all = helper(data_all, arr_rate)\n",
    "            max_bs = get_best_bs(data_all, time_budget)\n",
    "            algo_sol_df, tries, _ = main(data_train, data_infer, power_budget, 15, max_bs)\n",
    "            algo_sol_df = helper(algo_sol_df, arr_rate)\n",
    "            algo_sol_df.drop_duplicates(inplace=True)\n",
    "            algo_sol_df.sort_values(by=['observed_time_infer'], inplace=True)\n",
    "            tries += add_num_tries[max_bs]\n",
    "            pwd, bs, interleaved_power, infer_time, train_time, best_num_train_batches, tries = get_best_row_optim_algo(algo_sol_df, time_budget, power_budget, data_all, tries)\n",
    "            algo_df.loc[len(algo_df)] = [pwd, infer_time, bs, interleaved_power,power_budget, best_num_train_batches, tries, time_budget, arr_rate]\n",
    "    print(\"Arr Rate: \", arr_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cores</th>\n",
       "      <th>cpu</th>\n",
       "      <th>gpu</th>\n",
       "      <th>mem</th>\n",
       "      <th>observed_time_train</th>\n",
       "      <th>observed_power_train</th>\n",
       "      <th>observed_time_infer</th>\n",
       "      <th>bs</th>\n",
       "      <th>observed_power_infer</th>\n",
       "      <th>interleaved_power</th>\n",
       "      <th>interleaved_time</th>\n",
       "      <th>powermode</th>\n",
       "      <th>observed_time_infer_scaled</th>\n",
       "      <th>observed_time_train_scaled</th>\n",
       "      <th>num_train_batches</th>\n",
       "      <th>time_cond1</th>\n",
       "      <th>time_cond2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>8</td>\n",
       "      <td>1958400</td>\n",
       "      <td>1300500000</td>\n",
       "      <td>3199000000</td>\n",
       "      <td>58.787088</td>\n",
       "      <td>49.6870</td>\n",
       "      <td>1820.782166</td>\n",
       "      <td>32.0</td>\n",
       "      <td>62.1075</td>\n",
       "      <td>62.1075</td>\n",
       "      <td>1879.569254</td>\n",
       "      <td>8_1958400_1300500000_3199000000</td>\n",
       "      <td>1.820782</td>\n",
       "      <td>0.058787</td>\n",
       "      <td>5</td>\n",
       "      <td>3.954115</td>\n",
       "      <td>27.311732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>8</td>\n",
       "      <td>1958400</td>\n",
       "      <td>1134750000</td>\n",
       "      <td>3199000000</td>\n",
       "      <td>62.776337</td>\n",
       "      <td>43.6230</td>\n",
       "      <td>1975.849976</td>\n",
       "      <td>32.0</td>\n",
       "      <td>53.7090</td>\n",
       "      <td>53.7090</td>\n",
       "      <td>2038.626312</td>\n",
       "      <td>8_1958400_1134750000_3199000000</td>\n",
       "      <td>1.975850</td>\n",
       "      <td>0.062776</td>\n",
       "      <td>2</td>\n",
       "      <td>4.109183</td>\n",
       "      <td>29.637750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>8</td>\n",
       "      <td>1344000</td>\n",
       "      <td>1300500000</td>\n",
       "      <td>2133000000</td>\n",
       "      <td>76.530064</td>\n",
       "      <td>39.6160</td>\n",
       "      <td>2672.647949</td>\n",
       "      <td>32.0</td>\n",
       "      <td>48.7290</td>\n",
       "      <td>48.7290</td>\n",
       "      <td>2749.178013</td>\n",
       "      <td>8_1344000_1300500000_2133000000</td>\n",
       "      <td>2.672648</td>\n",
       "      <td>0.076530</td>\n",
       "      <td>-8</td>\n",
       "      <td>4.805981</td>\n",
       "      <td>40.089719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>8</td>\n",
       "      <td>1958400</td>\n",
       "      <td>726750000</td>\n",
       "      <td>3199000000</td>\n",
       "      <td>83.382557</td>\n",
       "      <td>32.7960</td>\n",
       "      <td>2769.798096</td>\n",
       "      <td>32.0</td>\n",
       "      <td>37.4010</td>\n",
       "      <td>37.4010</td>\n",
       "      <td>2853.180653</td>\n",
       "      <td>8_1958400_726750000_3199000000</td>\n",
       "      <td>2.769798</td>\n",
       "      <td>0.083383</td>\n",
       "      <td>-8</td>\n",
       "      <td>4.903131</td>\n",
       "      <td>41.546971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>8</td>\n",
       "      <td>1344000</td>\n",
       "      <td>726750000</td>\n",
       "      <td>3199000000</td>\n",
       "      <td>85.293392</td>\n",
       "      <td>29.4360</td>\n",
       "      <td>2874.541382</td>\n",
       "      <td>32.0</td>\n",
       "      <td>36.6990</td>\n",
       "      <td>36.6990</td>\n",
       "      <td>2959.834774</td>\n",
       "      <td>8_1344000_726750000_3199000000</td>\n",
       "      <td>2.874541</td>\n",
       "      <td>0.085293</td>\n",
       "      <td>-9</td>\n",
       "      <td>5.007875</td>\n",
       "      <td>43.118121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>12</td>\n",
       "      <td>1344000</td>\n",
       "      <td>726750000</td>\n",
       "      <td>2133000000</td>\n",
       "      <td>96.757072</td>\n",
       "      <td>28.1000</td>\n",
       "      <td>2954.821899</td>\n",
       "      <td>32.0</td>\n",
       "      <td>33.6120</td>\n",
       "      <td>33.6120</td>\n",
       "      <td>3051.578972</td>\n",
       "      <td>12_1344000_726750000_2133000000</td>\n",
       "      <td>2.954822</td>\n",
       "      <td>0.096757</td>\n",
       "      <td>-9</td>\n",
       "      <td>5.088155</td>\n",
       "      <td>44.322328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>8</td>\n",
       "      <td>2201600</td>\n",
       "      <td>726750000</td>\n",
       "      <td>2133000000</td>\n",
       "      <td>93.919346</td>\n",
       "      <td>30.1910</td>\n",
       "      <td>2975.308716</td>\n",
       "      <td>32.0</td>\n",
       "      <td>34.4140</td>\n",
       "      <td>34.4140</td>\n",
       "      <td>3069.228062</td>\n",
       "      <td>8_2201600_726750000_2133000000</td>\n",
       "      <td>2.975309</td>\n",
       "      <td>0.093919</td>\n",
       "      <td>-9</td>\n",
       "      <td>5.108642</td>\n",
       "      <td>44.629631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>8</td>\n",
       "      <td>1958400</td>\n",
       "      <td>726750000</td>\n",
       "      <td>2133000000</td>\n",
       "      <td>94.621983</td>\n",
       "      <td>28.7515</td>\n",
       "      <td>3009.859131</td>\n",
       "      <td>32.0</td>\n",
       "      <td>34.0120</td>\n",
       "      <td>34.0120</td>\n",
       "      <td>3104.481113</td>\n",
       "      <td>8_1958400_726750000_2133000000</td>\n",
       "      <td>3.009859</td>\n",
       "      <td>0.094622</td>\n",
       "      <td>-10</td>\n",
       "      <td>5.143192</td>\n",
       "      <td>45.147887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>8</td>\n",
       "      <td>1344000</td>\n",
       "      <td>726750000</td>\n",
       "      <td>2133000000</td>\n",
       "      <td>97.262112</td>\n",
       "      <td>28.0950</td>\n",
       "      <td>3032.607544</td>\n",
       "      <td>32.0</td>\n",
       "      <td>33.1180</td>\n",
       "      <td>33.1180</td>\n",
       "      <td>3129.869656</td>\n",
       "      <td>8_1344000_726750000_2133000000</td>\n",
       "      <td>3.032608</td>\n",
       "      <td>0.097262</td>\n",
       "      <td>-10</td>\n",
       "      <td>5.165941</td>\n",
       "      <td>45.489113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     cores      cpu         gpu         mem  observed_time_train  \\\n",
       "253      8  1958400  1300500000  3199000000            58.787088   \n",
       "256      8  1958400  1134750000  3199000000            62.776337   \n",
       "210      8  1344000  1300500000  2133000000            76.530064   \n",
       "262      8  1958400   726750000  3199000000            83.382557   \n",
       "220      8  1344000   726750000  3199000000            85.293392   \n",
       "366     12  1344000   726750000  2133000000            96.757072   \n",
       "282      8  2201600   726750000  2133000000            93.919346   \n",
       "261      8  1958400   726750000  2133000000            94.621983   \n",
       "219      8  1344000   726750000  2133000000            97.262112   \n",
       "\n",
       "     observed_power_train  observed_time_infer    bs  observed_power_infer  \\\n",
       "253               49.6870          1820.782166  32.0               62.1075   \n",
       "256               43.6230          1975.849976  32.0               53.7090   \n",
       "210               39.6160          2672.647949  32.0               48.7290   \n",
       "262               32.7960          2769.798096  32.0               37.4010   \n",
       "220               29.4360          2874.541382  32.0               36.6990   \n",
       "366               28.1000          2954.821899  32.0               33.6120   \n",
       "282               30.1910          2975.308716  32.0               34.4140   \n",
       "261               28.7515          3009.859131  32.0               34.0120   \n",
       "219               28.0950          3032.607544  32.0               33.1180   \n",
       "\n",
       "     interleaved_power  interleaved_time                        powermode  \\\n",
       "253            62.1075       1879.569254  8_1958400_1300500000_3199000000   \n",
       "256            53.7090       2038.626312  8_1958400_1134750000_3199000000   \n",
       "210            48.7290       2749.178013  8_1344000_1300500000_2133000000   \n",
       "262            37.4010       2853.180653   8_1958400_726750000_3199000000   \n",
       "220            36.6990       2959.834774   8_1344000_726750000_3199000000   \n",
       "366            33.6120       3051.578972  12_1344000_726750000_2133000000   \n",
       "282            34.4140       3069.228062   8_2201600_726750000_2133000000   \n",
       "261            34.0120       3104.481113   8_1958400_726750000_2133000000   \n",
       "219            33.1180       3129.869656   8_1344000_726750000_2133000000   \n",
       "\n",
       "     observed_time_infer_scaled  observed_time_train_scaled  \\\n",
       "253                    1.820782                    0.058787   \n",
       "256                    1.975850                    0.062776   \n",
       "210                    2.672648                    0.076530   \n",
       "262                    2.769798                    0.083383   \n",
       "220                    2.874541                    0.085293   \n",
       "366                    2.954822                    0.096757   \n",
       "282                    2.975309                    0.093919   \n",
       "261                    3.009859                    0.094622   \n",
       "219                    3.032608                    0.097262   \n",
       "\n",
       "     num_train_batches  time_cond1  time_cond2  \n",
       "253                  5    3.954115   27.311732  \n",
       "256                  2    4.109183   29.637750  \n",
       "210                 -8    4.805981   40.089719  \n",
       "262                 -8    4.903131   41.546971  \n",
       "220                 -9    5.007875   43.118121  \n",
       "366                 -9    5.088155   44.322328  \n",
       "282                 -9    5.108642   44.629631  \n",
       "261                -10    5.143192   45.147887  \n",
       "219                -10    5.165941   45.489113  "
      ]
     },
     "execution_count": 786,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo_sol_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 787,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None, None, None, None, None, 19)"
      ]
     },
     "execution_count": 787,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_best_row_optim_algo(algo_sol_df, 1, 15, data_all, tries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 788,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_df = pd.DataFrame(columns=['powermode','infer_time','bs','interleaved_power','power_budget','num_train_batches','num_tries','time_budget', 'arr_rate'])\n",
    "# time_list = [1]\n",
    "# power_list = [20]\n",
    "for arr_rate in arr_rate_list:\n",
    "    for time_budget in time_list:\n",
    "        for power_budget in power_list:\n",
    "            data = pd.merge(data_train, data_infer, on=['cores', 'gpu', 'cpu', 'mem'], suffixes=('_train', '_infer'))\n",
    "            data  = helper(data, arr_rate)\n",
    "            pwd, bs, interleaved_power, infer_time, train_time, best_num_train_batches, tries = get_best_row_optim(data, time_budget, power_budget)\n",
    "            optim_df.loc[len(optim_df)] = [pwd, infer_time, bs, interleaved_power,power_budget, best_num_train_batches, tries, time_budget, arr_rate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 789,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optim_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 790,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>powermode</th>\n",
       "      <th>infer_time</th>\n",
       "      <th>bs</th>\n",
       "      <th>interleaved_power</th>\n",
       "      <th>power_budget</th>\n",
       "      <th>num_train_batches</th>\n",
       "      <th>num_tries</th>\n",
       "      <th>time_budget</th>\n",
       "      <th>arr_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6880</th>\n",
       "      <td>8_1344000_1134750000_3199000000</td>\n",
       "      <td>1956.751709</td>\n",
       "      <td>32.0</td>\n",
       "      <td>53.81</td>\n",
       "      <td>56.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6881</th>\n",
       "      <td>8_1344000_1134750000_3199000000</td>\n",
       "      <td>1956.751709</td>\n",
       "      <td>32.0</td>\n",
       "      <td>53.81</td>\n",
       "      <td>57.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6882</th>\n",
       "      <td>8_1344000_1134750000_3199000000</td>\n",
       "      <td>1956.751709</td>\n",
       "      <td>32.0</td>\n",
       "      <td>53.81</td>\n",
       "      <td>58.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6883</th>\n",
       "      <td>8_1344000_1134750000_3199000000</td>\n",
       "      <td>1956.751709</td>\n",
       "      <td>32.0</td>\n",
       "      <td>53.81</td>\n",
       "      <td>59.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6884</th>\n",
       "      <td>8_1344000_1134750000_3199000000</td>\n",
       "      <td>1956.751709</td>\n",
       "      <td>32.0</td>\n",
       "      <td>53.81</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6885 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            powermode   infer_time    bs  interleaved_power  \\\n",
       "0                                 NaN          NaN   NaN                NaN   \n",
       "1                                 NaN          NaN   NaN                NaN   \n",
       "2                                 NaN          NaN   NaN                NaN   \n",
       "3                                 NaN          NaN   NaN                NaN   \n",
       "4                                 NaN          NaN   NaN                NaN   \n",
       "...                               ...          ...   ...                ...   \n",
       "6880  8_1344000_1134750000_3199000000  1956.751709  32.0              53.81   \n",
       "6881  8_1344000_1134750000_3199000000  1956.751709  32.0              53.81   \n",
       "6882  8_1344000_1134750000_3199000000  1956.751709  32.0              53.81   \n",
       "6883  8_1344000_1134750000_3199000000  1956.751709  32.0              53.81   \n",
       "6884  8_1344000_1134750000_3199000000  1956.751709  32.0              53.81   \n",
       "\n",
       "      power_budget  num_train_batches  num_tries  time_budget  arr_rate  \n",
       "0             10.0                NaN        1.0          2.0       1.0  \n",
       "1             11.0                NaN        1.0          2.0       1.0  \n",
       "2             12.0                NaN        1.0          2.0       1.0  \n",
       "3             13.0                NaN        1.0          2.0       1.0  \n",
       "4             14.0                NaN        1.0          2.0       1.0  \n",
       "...            ...                ...        ...          ...       ...  \n",
       "6880          56.0                2.0        1.0          6.0      15.0  \n",
       "6881          57.0                2.0        1.0          6.0      15.0  \n",
       "6882          58.0                2.0        1.0          6.0      15.0  \n",
       "6883          59.0                2.0        1.0          6.0      15.0  \n",
       "6884          60.0                2.0        1.0          6.0      15.0  \n",
       "\n",
       "[6885 rows x 9 columns]"
      ]
     },
     "execution_count": 790,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optim_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 791,
   "metadata": {},
   "outputs": [],
   "source": [
    "# algo_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 792,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>powermode</th>\n",
       "      <th>infer_time</th>\n",
       "      <th>bs</th>\n",
       "      <th>interleaved_power</th>\n",
       "      <th>power_budget</th>\n",
       "      <th>num_train_batches</th>\n",
       "      <th>num_tries</th>\n",
       "      <th>time_budget</th>\n",
       "      <th>arr_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6880</th>\n",
       "      <td>8_1958400_1134750000_3199000000</td>\n",
       "      <td>1975.849976</td>\n",
       "      <td>32.0</td>\n",
       "      <td>53.709</td>\n",
       "      <td>56.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6881</th>\n",
       "      <td>8_1958400_1134750000_3199000000</td>\n",
       "      <td>1975.849976</td>\n",
       "      <td>32.0</td>\n",
       "      <td>53.709</td>\n",
       "      <td>57.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6882</th>\n",
       "      <td>8_1958400_1134750000_3199000000</td>\n",
       "      <td>1975.849976</td>\n",
       "      <td>32.0</td>\n",
       "      <td>53.709</td>\n",
       "      <td>58.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6883</th>\n",
       "      <td>8_1958400_1134750000_3199000000</td>\n",
       "      <td>1975.849976</td>\n",
       "      <td>32.0</td>\n",
       "      <td>53.709</td>\n",
       "      <td>59.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6884</th>\n",
       "      <td>8_1958400_1134750000_3199000000</td>\n",
       "      <td>1975.849976</td>\n",
       "      <td>32.0</td>\n",
       "      <td>53.709</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6885 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            powermode   infer_time    bs  interleaved_power  \\\n",
       "0                                 NaN          NaN   NaN                NaN   \n",
       "1                                 NaN          NaN   NaN                NaN   \n",
       "2                                 NaN          NaN   NaN                NaN   \n",
       "3                                 NaN          NaN   NaN                NaN   \n",
       "4                                 NaN          NaN   NaN                NaN   \n",
       "...                               ...          ...   ...                ...   \n",
       "6880  8_1958400_1134750000_3199000000  1975.849976  32.0             53.709   \n",
       "6881  8_1958400_1134750000_3199000000  1975.849976  32.0             53.709   \n",
       "6882  8_1958400_1134750000_3199000000  1975.849976  32.0             53.709   \n",
       "6883  8_1958400_1134750000_3199000000  1975.849976  32.0             53.709   \n",
       "6884  8_1958400_1134750000_3199000000  1975.849976  32.0             53.709   \n",
       "\n",
       "      power_budget  num_train_batches  num_tries  time_budget  arr_rate  \n",
       "0             10.0                NaN       15.0          2.0       1.0  \n",
       "1             11.0                NaN       15.0          2.0       1.0  \n",
       "2             12.0                NaN       15.0          2.0       1.0  \n",
       "3             13.0                NaN       15.0          2.0       1.0  \n",
       "4             14.0                NaN       15.0          2.0       1.0  \n",
       "...            ...                ...        ...          ...       ...  \n",
       "6880          56.0                2.0       11.0          6.0      15.0  \n",
       "6881          57.0                2.0       11.0          6.0      15.0  \n",
       "6882          58.0                2.0       11.0          6.0      15.0  \n",
       "6883          59.0                2.0       11.0          6.0      15.0  \n",
       "6884          60.0                2.0       11.0          6.0      15.0  \n",
       "\n",
       "[6885 rows x 9 columns]"
      ]
     },
     "execution_count": 792,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 793,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge algo_df and optim_df based on power_budget and add suffixes _algo and _optim\n",
    "merged_df = pd.merge(algo_df, optim_df, on=['power_budget','time_budget','arr_rate'], suffixes=('_algo', '_optim'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 801,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>powermode_algo</th>\n",
       "      <th>infer_time_algo</th>\n",
       "      <th>bs_algo</th>\n",
       "      <th>interleaved_power_algo</th>\n",
       "      <th>power_budget</th>\n",
       "      <th>num_train_batches_algo</th>\n",
       "      <th>num_tries_algo</th>\n",
       "      <th>time_budget</th>\n",
       "      <th>arr_rate</th>\n",
       "      <th>powermode_optim</th>\n",
       "      <th>infer_time_optim</th>\n",
       "      <th>bs_optim</th>\n",
       "      <th>interleaved_power_optim</th>\n",
       "      <th>num_train_batches_optim</th>\n",
       "      <th>num_tries_optim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6880</th>\n",
       "      <td>8_1958400_1134750000_3199000000</td>\n",
       "      <td>1975.849976</td>\n",
       "      <td>32.0</td>\n",
       "      <td>53.709</td>\n",
       "      <td>56.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8_1344000_1134750000_3199000000</td>\n",
       "      <td>1956.751709</td>\n",
       "      <td>32.0</td>\n",
       "      <td>53.81</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6881</th>\n",
       "      <td>8_1958400_1134750000_3199000000</td>\n",
       "      <td>1975.849976</td>\n",
       "      <td>32.0</td>\n",
       "      <td>53.709</td>\n",
       "      <td>57.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8_1344000_1134750000_3199000000</td>\n",
       "      <td>1956.751709</td>\n",
       "      <td>32.0</td>\n",
       "      <td>53.81</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6882</th>\n",
       "      <td>8_1958400_1134750000_3199000000</td>\n",
       "      <td>1975.849976</td>\n",
       "      <td>32.0</td>\n",
       "      <td>53.709</td>\n",
       "      <td>58.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8_1344000_1134750000_3199000000</td>\n",
       "      <td>1956.751709</td>\n",
       "      <td>32.0</td>\n",
       "      <td>53.81</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6883</th>\n",
       "      <td>8_1958400_1134750000_3199000000</td>\n",
       "      <td>1975.849976</td>\n",
       "      <td>32.0</td>\n",
       "      <td>53.709</td>\n",
       "      <td>59.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8_1344000_1134750000_3199000000</td>\n",
       "      <td>1956.751709</td>\n",
       "      <td>32.0</td>\n",
       "      <td>53.81</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6884</th>\n",
       "      <td>8_1958400_1134750000_3199000000</td>\n",
       "      <td>1975.849976</td>\n",
       "      <td>32.0</td>\n",
       "      <td>53.709</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8_1344000_1134750000_3199000000</td>\n",
       "      <td>1956.751709</td>\n",
       "      <td>32.0</td>\n",
       "      <td>53.81</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6885 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       powermode_algo  infer_time_algo  bs_algo  \\\n",
       "0                                 NaN              NaN      NaN   \n",
       "1                                 NaN              NaN      NaN   \n",
       "2                                 NaN              NaN      NaN   \n",
       "3                                 NaN              NaN      NaN   \n",
       "4                                 NaN              NaN      NaN   \n",
       "...                               ...              ...      ...   \n",
       "6880  8_1958400_1134750000_3199000000      1975.849976     32.0   \n",
       "6881  8_1958400_1134750000_3199000000      1975.849976     32.0   \n",
       "6882  8_1958400_1134750000_3199000000      1975.849976     32.0   \n",
       "6883  8_1958400_1134750000_3199000000      1975.849976     32.0   \n",
       "6884  8_1958400_1134750000_3199000000      1975.849976     32.0   \n",
       "\n",
       "      interleaved_power_algo  power_budget  num_train_batches_algo  \\\n",
       "0                        NaN          10.0                     NaN   \n",
       "1                        NaN          11.0                     NaN   \n",
       "2                        NaN          12.0                     NaN   \n",
       "3                        NaN          13.0                     NaN   \n",
       "4                        NaN          14.0                     NaN   \n",
       "...                      ...           ...                     ...   \n",
       "6880                  53.709          56.0                     2.0   \n",
       "6881                  53.709          57.0                     2.0   \n",
       "6882                  53.709          58.0                     2.0   \n",
       "6883                  53.709          59.0                     2.0   \n",
       "6884                  53.709          60.0                     2.0   \n",
       "\n",
       "      num_tries_algo  time_budget  arr_rate                  powermode_optim  \\\n",
       "0               15.0          2.0       1.0                              NaN   \n",
       "1               15.0          2.0       1.0                              NaN   \n",
       "2               15.0          2.0       1.0                              NaN   \n",
       "3               15.0          2.0       1.0                              NaN   \n",
       "4               15.0          2.0       1.0                              NaN   \n",
       "...              ...          ...       ...                              ...   \n",
       "6880            11.0          6.0      15.0  8_1344000_1134750000_3199000000   \n",
       "6881            11.0          6.0      15.0  8_1344000_1134750000_3199000000   \n",
       "6882            11.0          6.0      15.0  8_1344000_1134750000_3199000000   \n",
       "6883            11.0          6.0      15.0  8_1344000_1134750000_3199000000   \n",
       "6884            11.0          6.0      15.0  8_1344000_1134750000_3199000000   \n",
       "\n",
       "      infer_time_optim  bs_optim  interleaved_power_optim  \\\n",
       "0                  NaN       NaN                      NaN   \n",
       "1                  NaN       NaN                      NaN   \n",
       "2                  NaN       NaN                      NaN   \n",
       "3                  NaN       NaN                      NaN   \n",
       "4                  NaN       NaN                      NaN   \n",
       "...                ...       ...                      ...   \n",
       "6880       1956.751709      32.0                    53.81   \n",
       "6881       1956.751709      32.0                    53.81   \n",
       "6882       1956.751709      32.0                    53.81   \n",
       "6883       1956.751709      32.0                    53.81   \n",
       "6884       1956.751709      32.0                    53.81   \n",
       "\n",
       "      num_train_batches_optim  num_tries_optim  \n",
       "0                         NaN              1.0  \n",
       "1                         NaN              1.0  \n",
       "2                         NaN              1.0  \n",
       "3                         NaN              1.0  \n",
       "4                         NaN              1.0  \n",
       "...                       ...              ...  \n",
       "6880                      2.0              1.0  \n",
       "6881                      2.0              1.0  \n",
       "6882                      2.0              1.0  \n",
       "6883                      2.0              1.0  \n",
       "6884                      2.0              1.0  \n",
       "\n",
       "[6885 rows x 15 columns]"
      ]
     },
     "execution_count": 801,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 795,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.710094408133624"
      ]
     },
     "execution_count": 795,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(merged_df['num_tries_algo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 796,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot a histogram of the number of tries for the algorithmic solution\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(merged_df['num_tries_algo'], bins=10)\n",
    "plt.xlabel('Number of Tries')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Number of Tries for Algorithmic Solution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 802,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2583"
      ]
     },
     "execution_count": 802,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df['num_train_batches_optim'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 799,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = time_budget*1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 800,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv(f'interleaved_{model_train}_train_{model_infer}_infer_multi_al.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
