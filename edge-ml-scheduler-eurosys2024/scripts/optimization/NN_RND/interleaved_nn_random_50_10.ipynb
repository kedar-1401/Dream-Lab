{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_pwds_50 = pd.read_csv(\"tl/e24_random_50_pwmds.csv\")\n",
    "sampled_pwds_50 = list(sampled_pwds_50['powermode'].values)\n",
    "\n",
    "sampled_pwds_10 = pd.read_csv(\"tl/e24_random_10_pwmds.csv\")\n",
    "sampled_pwds_10 = list(sampled_pwds_10['powermode'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train = 'lstm'\n",
    "model_infer = 'yolo'\n",
    "\n",
    "model_train = 'resnet'\n",
    "model_infer = 'bert'\n",
    "\n",
    "arr_rate_list = [30, 40, 50, 60, 70, 80, 90, 100, 110, 120]\n",
    "time_list = [0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 2.0]\n",
    "power_list = np.arange(10, 51, 1)\n",
    "\n",
    "time_list = [2, 2.5, 3, 3.5, 4, 4.5, 5, 5.5, 6]\n",
    "arr_rate_list = [1,2,3,4,5,6,7,8,9,10, 11, 12, 13, 14, 15]\n",
    "power_list = np.arange(10, 61, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(f'{model_train}_train_data_final.csv')\n",
    "data_infer = pd.read_csv(f'{model_infer}_infer_data_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "core_vals=[4, 8, 12] #3 possible values\n",
    "gpu_vals=[114750000, 318750000, 522750000, 726750000, 930750000, 1134750000, 1300500000]\n",
    "cpu_vals=[422400, 729600, 1036800, 1344000, 1651200, 1958400, 2201600] #in kHz, 7 possible values\n",
    "mem_vals = [665600000, 2133000000, 3199000000]\n",
    "bs_vals = [1, 4, 16, 32, 64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Filter data based on values in the list only\n",
    "data_train = data_train[data_train['cores'].isin(core_vals)]\n",
    "data_train = data_train[data_train['gpu'].isin(gpu_vals)]\n",
    "data_train = data_train[data_train['cpu'].isin(cpu_vals)]\n",
    "data_train = data_train[data_train['mem'].isin(mem_vals)]\n",
    "data_train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def helper(data, arr_rate):\n",
    "    data['interleaved_power'] = np.maximum(data['observed_power_train'], data['observed_power_infer'])\n",
    "    data['interleaved_time'] = data['observed_time_train'] + data['observed_time_infer']\n",
    "    data['powermode'] = data['cores'].astype(str) + \"_\" + data['cpu'].astype(str) + \"_\" + data['gpu'].astype(str) + \"_\" + data['mem'].astype(str)\n",
    "    data['observed_time_infer_scaled'] = data['observed_time_infer']/1000\n",
    "    data['observed_time_train_scaled'] = data['observed_time_train']/1000\n",
    "    data['num_train_batches'] = np.floor(((data['bs'].astype(int))/arr_rate - data['observed_time_infer_scaled'])/data['observed_time_train_scaled']).astype(int)\n",
    "    data['time_cond1'] = (data['bs'].astype(int))/arr_rate + data['observed_time_infer_scaled']\n",
    "    data['time_cond2'] = data['observed_time_infer_scaled']*arr_rate\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_row_optim(data, time_budget, power_budget):\n",
    "\n",
    "    data = data[data['interleaved_power'] <= power_budget]\n",
    "    data = data[data['time_cond1'] <= time_budget]\n",
    "    data = data[data['time_cond2'] <= data['bs']]\n",
    "\n",
    "\n",
    "    if data.empty:\n",
    "        return None, None, None, None, None, None\n",
    "    \n",
    "    else:     \n",
    "        data = data.sort_values(by=['num_train_batches'],ascending=False)\n",
    "\n",
    "        train_batch_vals = data['num_train_batches'].unique()\n",
    "        max_train_batch_val = max(train_batch_vals)\n",
    "\n",
    "        data = data[data['num_train_batches'] == max_train_batch_val]\n",
    "        data.sort_values(by=['observed_time_infer_scaled'], inplace=True)\n",
    "\n",
    "        data = data.iloc[0]\n",
    "        powermode = data['powermode']\n",
    "        bs = data['bs']\n",
    "        power = data['interleaved_power']\n",
    "        infer_time = data['observed_time_infer']\n",
    "        train_time = data['observed_time_train']\n",
    "        num_train_batches = data['num_train_batches']\n",
    "\n",
    "        return powermode, bs, power, infer_time, train_time, num_train_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_row_optim_nn(data, time_budget, power_budget):\n",
    "\n",
    "    data = data[data['predicted_interleaved_power'] <= power_budget]\n",
    "    data = data[data['predicted_time_cond1'] <= time_budget]\n",
    "    data = data[data['predicted_time_cond2'] <= data['bs']]\n",
    "\n",
    "\n",
    "    if data.empty:\n",
    "        return None, None, None, None, None, None\n",
    "    \n",
    "    else:     \n",
    "        data = data.sort_values(by=['predicted_num_train_batches'],ascending=False)\n",
    "\n",
    "        train_batch_vals = data['predicted_num_train_batches'].unique()\n",
    "        max_train_batch_val = max(train_batch_vals)\n",
    "\n",
    "        data = data[data['predicted_num_train_batches'] == max_train_batch_val]\n",
    "        data.sort_values(by=['predicted_time_infer_scaled'], inplace=True)\n",
    "\n",
    "        data = data.iloc[0]\n",
    "        powermode = data['powermode']\n",
    "        bs = data['bs']\n",
    "        power = data['observed_interleaved_power']\n",
    "        infer_time = data['observed_time_infer']\n",
    "        train_time = data['observed_time_train']\n",
    "        num_train_batches = data['observed_num_train_batches']\n",
    "\n",
    "        return powermode, bs, power, infer_time, train_time, num_train_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_train_pareto_df = pd.read_csv(f\"/home/saisamarth/exp/tl/e24_merged_observed_predicted_{model_train}_NN_sampled_50.csv\")\n",
    "nn_infer_pareto_df = pd.read_csv(f\"/home/saisamarth/exp/tl/e24_merged_observed_predicted_{model_train}_NN_infer_sampled_50.csv\")\n",
    "nn_train_pareto_df = nn_train_pareto_df[nn_train_pareto_df['powermode'].isin(sampled_pwds_50)]\n",
    "nn_infer_pareto_df = nn_infer_pareto_df[nn_infer_pareto_df['powermode'].isin(sampled_pwds_10)]\n",
    "nn_train_pareto_df.reset_index(inplace=True, drop=True)\n",
    "nn_infer_pareto_df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge nn_train_pareto_df and nn_infer_pareto_df based on powermode with suffixes _train and _infer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def helper_nn(data, arr_rate):\n",
    "    data['observed_interleaved_power'] = np.maximum(data['observed_power_train'], data['observed_power_infer'])\n",
    "    data['observed_interleaved_time'] = data['observed_time_train'] + data['observed_time_infer']\n",
    "    data['predicted_interleaved_power'] = np.maximum(data['predicted_power_train'], data['predicted_power_infer'])\n",
    "    data['predicted_interleaved_time'] = data['predicted_time_train'] + data['predicted_time_infer']\n",
    "\n",
    "    data['predicted_time_infer_scaled'] = data['predicted_time_infer']/1000\n",
    "    data['predicted_time_train_scaled'] = data['predicted_time_train']/1000\n",
    "    data['observed_time_infer_scaled'] = data['observed_time_infer']/1000\n",
    "    data['observed_time_train_scaled'] = data['observed_time_train']/1000\n",
    "\n",
    "    data['predicted_num_train_batches'] = np.floor(((data['bs'].astype(int))/arr_rate - data['predicted_time_infer_scaled'])/data['predicted_time_train_scaled']).astype(int)\n",
    "    data['observed_num_train_batches'] = np.floor(((data['bs'].astype(int))/arr_rate - data['observed_time_infer_scaled'])/data['observed_time_train_scaled']).astype(int)\n",
    "\n",
    "    data['predicted_time_cond1'] = (data['bs'].astype(int))/arr_rate + data['predicted_time_infer_scaled']\n",
    "    data['predicted_time_cond2'] = data['predicted_time_infer_scaled']*arr_rate\n",
    "\n",
    "    data['observed_time_cond1'] = (data['bs'].astype(int))/arr_rate + data['observed_time_infer_scaled']\n",
    "    data['observed_time_cond2'] = data['observed_time_infer_scaled']*arr_rate\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_result_df = pd.DataFrame(columns=['powermode','infer_time','bs','interleaved_power','power_budget','num_train_batches','time_budget', 'arr_rate'])\n",
    "# time_list = [1]\n",
    "# power_list = [20]\n",
    "for arr_rate in arr_rate_list:\n",
    "    for time_budget in time_list:\n",
    "        for power_budget in power_list:\n",
    "            nn_pareto_df = pd.merge(nn_train_pareto_df, nn_infer_pareto_df, on=['powermode'], suffixes=('_train', '_infer'))\n",
    "            nn_pareto_df = helper_nn(nn_pareto_df, arr_rate)\n",
    "            pwd, bs, interleaved_power, infer_time, train_time, best_num_train_batches = get_best_row_optim_nn(nn_pareto_df, time_budget, power_budget)\n",
    "            nn_result_df.loc[len(nn_result_df)] = [pwd, infer_time, bs, interleaved_power,power_budget, best_num_train_batches, time_budget, arr_rate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_result_df = pd.DataFrame(columns=['powermode','infer_time','bs','interleaved_power','power_budget','num_train_batches','time_budget','arr_rate'])\n",
    "# time_list = [1]\n",
    "# power_list = [20]\n",
    "for arr_rate in arr_rate_list:\n",
    "    for time_budget in time_list:\n",
    "        for power_budget in power_list:\n",
    "            # merge the data_train and data_infer based on cores, gpu, cpu, mem with suffixes _train and _infer\n",
    "            data_all = pd.merge(data_train, data_infer, on=['cores', 'gpu', 'cpu', 'mem'], suffixes=('_train', '_infer'))\n",
    "            data_all = helper(data_all,arr_rate)\n",
    "            data_all = data_all[data_all['powermode'].isin(sampled_pwds_10)]\n",
    "            pwd, bs, interleaved_power, infer_time, train_time, best_num_train_batches = get_best_row_optim(data_all, time_budget, power_budget)\n",
    "            random_result_df.loc[len(random_result_df)] = [pwd, infer_time, bs, interleaved_power,power_budget, best_num_train_batches, time_budget, arr_rate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_result_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>powermode</th>\n",
       "      <th>infer_time</th>\n",
       "      <th>bs</th>\n",
       "      <th>interleaved_power</th>\n",
       "      <th>power_budget</th>\n",
       "      <th>num_train_batches</th>\n",
       "      <th>time_budget</th>\n",
       "      <th>arr_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8_1344000_114750000_665600000</td>\n",
       "      <td>557.418243</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.3530</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8_1344000_114750000_2133000000</td>\n",
       "      <td>553.883423</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.1660</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>12_2201600_114750000_2133000000</td>\n",
       "      <td>552.249084</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.7560</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12_2201600_114750000_2133000000</td>\n",
       "      <td>552.249084</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.7560</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8_1344000_522750000_665600000</td>\n",
       "      <td>238.206413</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.8780</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5962</th>\n",
       "      <td>4_422400_930750000_3199000000</td>\n",
       "      <td>600.276215</td>\n",
       "      <td>8.0</td>\n",
       "      <td>41.9755</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5963</th>\n",
       "      <td>4_422400_930750000_3199000000</td>\n",
       "      <td>600.276215</td>\n",
       "      <td>8.0</td>\n",
       "      <td>41.9755</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5964</th>\n",
       "      <td>4_422400_930750000_3199000000</td>\n",
       "      <td>600.276215</td>\n",
       "      <td>8.0</td>\n",
       "      <td>41.9755</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5965</th>\n",
       "      <td>4_422400_930750000_3199000000</td>\n",
       "      <td>600.276215</td>\n",
       "      <td>8.0</td>\n",
       "      <td>41.9755</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5966</th>\n",
       "      <td>4_422400_930750000_3199000000</td>\n",
       "      <td>600.276215</td>\n",
       "      <td>8.0</td>\n",
       "      <td>41.9755</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3911 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            powermode  infer_time   bs  interleaved_power  \\\n",
       "6       8_1344000_114750000_665600000  557.418243  1.0            15.3530   \n",
       "7      8_1344000_114750000_2133000000  553.883423  1.0            16.1660   \n",
       "8     12_2201600_114750000_2133000000  552.249084  1.0            17.7560   \n",
       "9     12_2201600_114750000_2133000000  552.249084  1.0            17.7560   \n",
       "10      8_1344000_522750000_665600000  238.206413  1.0            19.8780   \n",
       "...                               ...         ...  ...                ...   \n",
       "5962    4_422400_930750000_3199000000  600.276215  8.0            41.9755   \n",
       "5963    4_422400_930750000_3199000000  600.276215  8.0            41.9755   \n",
       "5964    4_422400_930750000_3199000000  600.276215  8.0            41.9755   \n",
       "5965    4_422400_930750000_3199000000  600.276215  8.0            41.9755   \n",
       "5966    4_422400_930750000_3199000000  600.276215  8.0            41.9755   \n",
       "\n",
       "      power_budget  num_train_batches  time_budget  arr_rate  \n",
       "6             16.0                0.0          2.0       1.0  \n",
       "7             17.0                0.0          2.0       1.0  \n",
       "8             18.0                0.0          2.0       1.0  \n",
       "9             19.0                0.0          2.0       1.0  \n",
       "10            20.0                3.0          2.0       1.0  \n",
       "...            ...                ...          ...       ...  \n",
       "5962          56.0                0.0          6.0      13.0  \n",
       "5963          57.0                0.0          6.0      13.0  \n",
       "5964          58.0                0.0          6.0      13.0  \n",
       "5965          59.0                0.0          6.0      13.0  \n",
       "5966          60.0                0.0          6.0      13.0  \n",
       "\n",
       "[3911 rows x 8 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge nn_result_df and random_result_df based on power_budget and time_budget with suffixes _nn and _random\n",
    "result_df = pd.merge(nn_result_df, random_result_df, on=['power_budget', 'time_budget','arr_rate'], suffixes=('_nn', '_random'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv(f'interleaved_{model_train}_train_{model_infer}_infer_nn_alt_random_multi_al.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
